
## 1. Tool Definition & Schema

### Creating Tools with @tool Decorator

Tools are functions that the LLM can use to perform specific tasks. In LangChain, we use the `@tool` decorator to convert regular functions into structured tools.

```python
from langchain_core.tools import tool

@tool
def add(x: float, y: float) -> float:
    """Add 'x' and 'y'."""
    return x + y

@tool
def multiply(x: float, y: float) -> float:
    """Multiply 'x' and 'y'."""
    return x * y
```

**Key Points:**

- The `@tool` decorator transforms functions into `StructuredTool` objects
- Function docstrings become tool descriptions that help the LLM understand when to use them
- Type hints define the expected input types

### Understanding Args Schema

Each tool automatically gets an `args_schema` - a Pydantic model that defines the tool's input structure:

```python
# View tool properties
print(f"{add.name=}")           # Output: add.name='add'
print(f"{add.description=}")    # Output: add.description="Add 'x' and 'y'."

# Get JSON schema for the tool
add.args_schema.model_json_schema()
```

**Sample JSON Schema Output:**

```json
{
  "properties": {
    "x": {"title": "X", "type": "number"},
    "y": {"title": "Y", "type": "number"}
  },
  "required": ["x", "y"],
  "title": "addSchema",
  "type": "object"
}
```

### Sample Input JSON

When the LLM wants to use a tool, it outputs JSON that matches the schema:

```python
# Example LLM output for the add tool
llm_output_string = '{"x": 5, "y": 2}'
llm_output_dict = json.loads(llm_output_string)
# This becomes: {"x": 5, "y": 2}

# The tool is then called with these arguments
result = add.func(**llm_output_dict)  # Equivalent to add.func(x=5, y=2)
```

## 2. Making a Prompt with Agent Scratchpad

### Prompt Structure

The agent prompt needs specific placeholders to handle conversation flow and tool interactions:

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages([
    ("system", """
You are an assistant with access to tools for mathematical operations.
For any calculation, use the provided tools instead of computing yourself.
Respond only by invoking the appropriate tool.
"""),
    MessagesPlaceholder(variable_name="chat_history"),      # Previous conversation
    ("human", "{input}"),                                   # Current user input
    MessagesPlaceholder(variable_name="agent_scratchpad")   # Tool calls & results
])
```

**Key Components:**

- **System message**: Instructions for the agent's behavior
- **chat_history**: Maintains conversation context
- **input**: Current user question/request
- **agent_scratchpad**: Critical for tool execution - stores tool calls and their results

## 3. Making Agent with RunnableSerializable

### Agent Construction

The agent combines the prompt, LLM, and tools into a single executable unit:

```python
from langchain_core.runnables.base import RunnableSerializable

tools = [add, subtract, multiply, exponentiate]

agent: RunnableSerializable = (
    {
        "input": lambda x: x["input"],
        "chat_history": lambda x: x["chat_history"],
        "agent_scratchpad": lambda x: x.get("agent_scratchpad", [])
    }
    | prompt
    | llm.bind_tools(tools, tool_choice="any")
)
```

### Tool Choice Options

- **"any"**: Forces the LLM to always use a tool (cannot give direct answers)
- **"auto"**: LLM can choose whether to use a tool or provide a direct answer
- **"required"**: Similar to "any", must use a tool

**When to use each:**

- Use "any" when building custom executors with final_answer tools
- Use "auto" for more flexible agents that can answer without tools when appropriate

## 4. Making Tool Calls and Execution

### Step 1: Generate Tool Call

```python
tool_call = agent.invoke({"input": "What is 10 + 10", "chat_history": []})
print(tool_call.tool_calls)
# Output: [{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_123'}]
```

### Step 2: Execute Tool Separately

The agent doesn't automatically execute tools - you need to do this manually:

```python
# Create tool name to function mapping
name2tool = {tool.name: tool.func for tool in tools}

# Execute the tool
tool_name = tool_call.tool_calls[0]["name"]
tool_args = tool_call.tool_calls[0]["args"]
tool_result = name2tool[tool_name](**tool_args)
# Result: 20
```

### Step 3: Add Result to Scratchpad

```python
from langchain_core.messages import ToolMessage

tool_exec = ToolMessage(
    content=f"The {tool_name} tool returned {tool_result}",
    tool_call_id=tool_call.tool_calls[0]["id"]
)

# Pass back to agent with updated scratchpad
final_response = agent.invoke({
    "input": "What is 10 + 10",
    "chat_history": [],
    "agent_scratchpad": [tool_call, tool_exec]
})
```

## 5. Making a Final Answer Tool for Custom Executor

### Why Use a Final Answer Tool?

When using `tool_choice="any"`, the LLM must always use a tool. A final answer tool provides:

- **Control**: Prevents the LLM from giving direct answers when inappropriate
- **Structure**: Enforces specific output formats
- **Consistency**: Ensures all responses go through the same path

### Creating the Final Answer Tool

```python
@tool
def final_answer(answer: str, tools_used: list[str]) -> str:
    """Use this tool to provide a final answer to the user.
    The answer should be in natural language as this will be provided
    to the user directly. The tools_used must include a list of tool
    names that were used within the scratchpad.
    """
    return {"answer": answer, "tools_used": tools_used}

# Add to tools list
tools = [final_answer, add, subtract, multiply, exponentiate]
```

### How It Works

1. Agent performs calculations using math tools
2. When ready to respond, agent calls `final_answer` tool
3. Executor detects `final_answer` call and stops execution
4. Returns structured response to user

## 6. Building a Custom Agent Execution Loop

### The Complete Custom Executor Class

```python
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

class CustomAgentExecutor:
    def __init__(self, max_iterations: int = 3):
        self.chat_history = []
        self.max_iterations = max_iterations
        self.agent = (
            {
                "input": lambda x: x["input"],
                "chat_history": lambda x: x["chat_history"],
                "agent_scratchpad": lambda x: x.get("agent_scratchpad", [])
            }
            | prompt
            | llm.bind_tools(tools, tool_choice="any")
        )

    def invoke(self, input: str) -> dict:
        count = 0
        agent_scratchpad = []
        
        while count < self.max_iterations:
            # 1. Generate tool call
            tool_call = self.agent.invoke({
                "input": input,
                "chat_history": self.chat_history,
                "agent_scratchpad": agent_scratchpad
            })
            
            # 2. Add tool call to scratchpad
            agent_scratchpad.append(tool_call)
            
            # 3. Execute the tool
            tool_name = tool_call.tool_calls[0]["name"]
            tool_args = tool_call.tool_calls[0]["args"]
            tool_call_id = tool_call.tool_calls[0]["id"]
            tool_out = name2tool[tool_name](**tool_args)
            
            # 4. Add tool result to scratchpad
            tool_exec = ToolMessage(
                content=f"{tool_out}",
                tool_call_id=tool_call_id
            )
            agent_scratchpad.append(tool_exec)
            
            print(f"{count}: {tool_name}({tool_args})")
            count += 1
            
            # 5. Check if we're done
            if tool_name == "final_answer":
                break
        
        # 6. Update chat history and return result
        final_answer = tool_out["answer"]
        self.chat_history.extend([
            HumanMessage(content=input),
            AIMessage(content=final_answer)
        ])
        
        return json.dumps(tool_out)
```

### Key Components Explained

**Initialization:**

- `max_iterations`: Prevents infinite loops
- `chat_history`: Maintains conversation context
- `agent`: The configured LangChain agent

**Execution Loop:**

1. **Generate tool call**: Agent decides what tool to use
2. **Add to scratchpad**: Keep track of the tool call
3. **Execute tool**: Actually run the tool function
4. **Add result**: Store the tool's output
5. **Check completion**: Stop if final_answer tool was used
6. **Update history**: Save the conversation for future context

**Usage:**

```python
agent_executor = CustomAgentExecutor()
result = agent_executor.invoke("What is 10 + 10")
# Output: {"answer": "10 + 10 equals 20", "tools_used": ["add"]}
```

### Benefits of Custom Execution

- **Full Control**: You decide exactly how tools are executed
- **Debugging**: Easy to add logging and error handling
- **Flexibility**: Can modify behavior for specific use cases
- **Performance**: Optimize for your specific requirements

This approach gives you complete control over the agent's behavior while leveraging LangChain's powerful tool and prompt management capabilities.