## What is Docker Compose?

Docker Compose is a tool for defining and running multi-container Docker applications. It uses a YAML file to configure your application's services, networks, and volumes. It's primarily a **development and testing tool**, not meant for production environments.

## The docker-compose.yml File Structure

### Basic Structure Overview

```yaml
version: '3.8'  # Compose file format version

services:       # Define your containers here
  service1:
    # Service configuration
  service2:
    # Service configuration

volumes:        # Define named volumes (optional)
  volume1:

networks:       # Define custom networks (optional)
  network1:
```

## 1. Version Line

The first line specifies the Compose file format version:

```yaml
version: '3.8'  # Recommended - supports latest features
```

**Beginner Tip:** Always use version 3.8 or higher for new projects. Older versions (like 1.0) lack many modern features.

## 2. Services Section

Services define the containers that make up your application.

### Service Names

Service names become the container names and hostnames for inter-container communication:

```yaml
services:
  frontend:     # This becomes hostname 'frontend'
    # configuration
  backend:      # This becomes hostname 'backend'
    # configuration
  database:     # This becomes hostname 'database'
    # configuration
```

### Common Service Configuration Options

#### 2.1 Image

Specifies which Docker image to use:

```yaml
services:
  web:
    image: nginx:latest        # Use official nginx image
  app:
    image: node:16-alpine      # Use Node.js 16 on Alpine Linux
  db:
    image: postgres:13         # Use PostgreSQL 13
```

#### 2.2 Ports

Maps ports from container to host machine:

```yaml
services:
  web:
    image: nginx
    ports:
      - "8080:80"              # host:container
      - "443:443"
  api:
    image: node:16
    ports:
      - "3000:3000"            # API runs on port 3000
```

**Format:** `"host_port:container_port"`

#### 2.3 Environment Variables

Set environment variables for the container:

```yaml
services:
  database:
    image: postgres:13
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: secret123
      NODE_ENV: development
    # Alternative syntax using list:
    # environment:
    #   - POSTGRES_DB=myapp
    #   - POSTGRES_USER=admin
```

#### 2.4 Commands

Override the default command that runs in the container:

```yaml
services:
  web:
    image: node:16
    command: npm run dev        # Override default command
  worker:
    image: node:16
    command: ["npm", "run", "worker"]  # Array syntax
```

#### 2.5 Volumes

Mount files/directories between host and container:

```yaml
services:
  web:
    image: node:16
    volumes:
      - ./src:/app/src          # Bind mount: host:container
      - node_modules:/app/node_modules  # Named volume
      - /app/logs               # Anonymous volume
```

**Types of volumes:**

- **Bind mount:** `./host/path:/container/path` - syncs with host directory
- **Named volume:** `volume_name:/container/path` - managed by Docker
- **Anonymous volume:** `/container/path` - temporary storage

#### 2.6 Networks

Connect services to custom networks:

```yaml
services:
  web:
    networks:
      - frontend
      - backend
  db:
    networks:
      - backend

networks:
  frontend:
  backend:
```

## 3. Additional Top-Level Sections

### Volumes

Define named volumes that can be shared between services:

```yaml
volumes:
  postgres_data:              # Named volume for database
  node_modules:               # Shared node_modules
  app_logs:

services:
  db:
    volumes:
      - postgres_data:/var/lib/postgresql/data
  web:
    volumes:
      - node_modules:/app/node_modules
      - app_logs:/app/logs
```

### Networks

Create custom networks for service communication:

```yaml
networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true             # No external access

services:
  web:
    networks:
      - frontend
  api:
    networks:
      - frontend
      - backend
  db:
    networks:
      - backend               # Only accessible from backend
```

## Docker Compose CLI Commands

### Basic Commands

**Start all services:**

```bash
docker compose up
docker compose up -d          # Run in background (detached)
```

**Stop all services:**

```bash
docker compose down
docker compose down -v        # Also remove volumes
docker compose down --rmi all # Also remove images
```

**View running services:**

```bash
docker compose ps
```

**View logs:**

```bash
docker compose logs
docker compose logs web       # Logs for specific service
docker compose logs -f        # Follow logs in real-time
```

### Building Images

**Build images defined in compose file:**

```bash
docker compose build
docker compose build web      # Build specific service
docker compose build --no-cache  # Force rebuild
```

**Build and start:**

```bash
docker compose up --build     # Build before starting
```

## Adding Image Building to Compose Files

Instead of using pre-built images, you can build from Dockerfiles in separate folders.

### Project Structure with Separate Folders

```
my-project/
├── docker-compose.yml
├── frontend/
│   ├── Dockerfile
│   ├── package.json
│   └── src/
├── backend/
│   ├── Dockerfile
│   ├── package.json
│   └── src/
├── redis/
│   └── Dockerfile (optional - usually use official image)
└── database/
    └── init.sql (optional initialization scripts)
```

### Build Configuration Options

```yaml
services:
  # Simple build - uses Dockerfile in specified directory
  frontend:
    build: ./frontend          # Build from ./frontend/Dockerfile
    ports:
      - "3000:3000"
  
  # Advanced build configuration
  backend:
    build:
      context: ./backend       # Build context directory
      dockerfile: Dockerfile   # Dockerfile name (default: Dockerfile)
      args:                    # Build-time arguments
        NODE_ENV: development
        API_VERSION: v1
      target: development      # Multi-stage build target
    ports:
      - "4000:4000"
  
  # Using official image (no build needed)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
```

### How Docker Build Context Works

The **build context** is the directory Docker uses to build your image:

- **Context Path:** `./frontend` means Docker can access files in the frontend folder
- **Dockerfile Location:** By default, looks for `Dockerfile` in the context directory
- **File Access:** Dockerfile can only access files within the context directory

### Example Dockerfiles for Each Service

**Frontend Dockerfile (./frontend/Dockerfile):**

```dockerfile
FROM node:18-alpine
WORKDIR /app

# Copy package files first (for layer caching)
COPY package*.json ./
RUN npm install

# Copy source code
COPY . .

# Expose port
EXPOSE 3000

# Start development server
CMD ["npm", "start"]
```

**Backend Dockerfile (./backend/Dockerfile):**

```dockerfile
FROM node:18-alpine
WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm install

# Copy application code
COPY . .

# Expose API port
EXPOSE 4000

# Start the server
CMD ["npm", "run", "dev"]
```

**Custom Redis Dockerfile (./redis/Dockerfile) - Optional:**

```dockerfile
FROM redis:7-alpine

# Copy custom redis configuration if needed
COPY redis.conf /usr/local/etc/redis/redis.conf

# Expose port
EXPOSE 6379

# Start redis with custom config
CMD ["redis-server", "/usr/local/etc/redis/redis.conf"]
```

## Container Communication Best Practices

### Service Names as Hostnames

Services can communicate using service names as hostnames:

```yaml
services:
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - API_URL=http://backend:4000  # Use service name 'backend'
  
  backend:
    build: ./backend
    ports:
      - "4000:4000"
    environment:
      - DB_HOST=database             # Use service name 'database'
      - DB_PORT=5432
  
  database:
    image: postgres:13
    environment:
      POSTGRES_DB: myapp
```

### Frontend Code Example

**React frontend connecting to backend:**

```javascript
// In your React app
const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:4000';

fetch(`${API_BASE_URL}/api/users`)
  .then(response => response.json())
  .then(data => console.log(data));
```

**Environment variables in docker-compose.yml:**

```yaml
services:
  frontend:
    build: ./frontend
    environment:
      - REACT_APP_API_URL=http://backend:4000
```

### Backend Code Example

**Node.js backend connecting to database:**

```javascript
// In your Node.js app
const dbConfig = {
  host: process.env.DB_HOST || 'localhost',
  port: process.env.DB_PORT || 5432,
  database: process.env.DB_NAME || 'myapp',
  user: process.env.DB_USER || 'admin',
  password: process.env.DB_PASSWORD || 'secret'
};
```

### Network Isolation Best Practices

```yaml
services:
  # Public-facing services
  nginx:
    image: nginx
    ports:
      - "80:80"
    networks:
      - frontend

  # Application services
  web:
    build: ./web
    networks:
      - frontend
      - backend
    environment:
      - API_URL=http://api:3000

  api:
    build: ./api
    networks:
      - backend
    environment:
      - DB_HOST=database

  # Database (not exposed to frontend)
  database:
    image: postgres:13
    networks:
      - backend
    environment:
      POSTGRES_DB: myapp

networks:
  frontend:
  backend:
    internal: false  # Set to true to block external access
```

## Complete Multi-Service Example with Separate Folders

Here's a complete docker-compose.yml for a project with separate frontend, backend, and Redis folders:

```yaml
version: '3.8'

services:
  # Frontend React application
  frontend:
    build:
      context: ./frontend      # Build from frontend folder
      dockerfile: Dockerfile
      args:
        NODE_ENV: development
    ports:
      - "3000:3000"
    volumes:
      - ./frontend/src:/app/src           # Live reload for development
      - frontend_modules:/app/node_modules
    environment:
      - REACT_APP_API_URL=http://backend:4000
      - REACT_APP_REDIS_HOST=redis
    networks:
      - frontend_network
    depends_on:
      - backend

  # Backend API service
  backend:
    build:
      context: ./backend       # Build from backend folder
      dockerfile: Dockerfile
      args:
        NODE_ENV: development
    ports:
      - "4000:4000"
    volumes:
      - ./backend/src:/app/src            # Live reload for development
      - backend_modules:/app/node_modules
    environment:
      - NODE_ENV=development
      - DB_HOST=database
      - DB_PORT=5432
      - DB_NAME=myapp
      - DB_USER=admin
      - DB_PASSWORD=secret123
      - REDIS_HOST=redis       # Redis connection
      - REDIS_PORT=6379
    networks:
      - frontend_network
      - backend_network
    depends_on:
      - database
      - redis

  # Redis cache service
  redis:
    build:
      context: ./redis         # Build custom Redis if needed
    # OR use official image:
    # image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - backend_network
    command: redis-server --appendonly yes  # Enable persistence

  # PostgreSQL database
  database:
    image: postgres:15
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: secret123
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - backend_network
    ports:
      - "5432:5432"            # Optional: for database tools

volumes:
  postgres_data:
  redis_data:
  frontend_modules:
  backend_modules:

networks:
  frontend_network:
  backend_network:
```

## Building and Communication Setup

### Step 1: Build All Services

```bash
# Build all services defined with 'build' configuration
docker compose build

# Build specific service
docker compose build frontend
docker compose build backend

# Force rebuild (ignore cache)
docker compose build --no-cache

# Build and start services
docker compose up --build
```

### Step 2: Service Communication Configuration

**Frontend Code (React - connecting to backend and Redis via backend):**

```javascript
// frontend/src/config/api.js
const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:4000';

export const apiClient = {
  // Backend API calls
  async getUsers() {
    const response = await fetch(`${API_BASE_URL}/api/users`);
    return response.json();
  },
  
  // Cache status via backend
  async getCacheStatus() {
    const response = await fetch(`${API_BASE_URL}/api/cache/status`);
    return response.json();
  }
};
```

**Backend Code (Node.js - connecting to database and Redis):**

```javascript
// backend/src/config/database.js
const { Pool } = require('pg');

const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: process.env.DB_PORT || 5432,
  database: process.env.DB_NAME || 'myapp',
  user: process.env.DB_USER || 'admin',
  password: process.env.DB_PASSWORD || 'secret',
});

// backend/src/config/redis.js
const redis = require('redis');

const client = redis.createClient({
  host: process.env.REDIS_HOST || 'localhost',
  port: process.env.REDIS_PORT || 6379,
});

client.on('connect', () => {
  console.log('Connected to Redis');
});

module.exports = { pool, redisClient: client };
```

**Backend API Routes with Redis Caching:**

```javascript
// backend/src/routes/users.js
const express = require('express');
const { pool, redisClient } = require('../config/database');
const router = express.Router();

// Get users with Redis caching
router.get('/users', async (req, res) => {
  try {
    // Check Redis cache first
    const cachedUsers = await redisClient.get('users');
    if (cachedUsers) {
      return res.json(JSON.parse(cachedUsers));
    }

    // If not in cache, get from database
    const result = await pool.query('SELECT * FROM users');
    const users = result.rows;

    // Store in Redis cache for 5 minutes
    await redisClient.setex('users', 300, JSON.stringify(users));

    res.json(users);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Cache status endpoint
router.get('/cache/status', async (req, res) => {
  try {
    const info = await redisClient.info();
    res.json({ status: 'connected', info });
  } catch (error) {
    res.json({ status: 'disconnected', error: error.message });
  }
});

module.exports = router;
```

### Step 3: Environment Variables for Communication

**Frontend Environment (.env in frontend folder):**

```bash
REACT_APP_API_URL=http://backend:4000
```

**Backend Environment (.env in backend folder):**

```bash
NODE_ENV=development
DB_HOST=database
DB_PORT=5432
DB_NAME=myapp
DB_USER=admin
DB_PASSWORD=secret123
REDIS_HOST=redis
REDIS_PORT=6379
PORT=4000
```

### Step 4: Development Workflow

```bash
# Start all services
docker compose up

# Start in background
docker compose up -d

# View logs for all services
docker compose logs

# View logs for specific service
docker compose logs frontend
docker compose logs backend
docker compose logs redis

# Rebuild specific service when Dockerfile changes
docker compose build backend
docker compose up -d backend

# Stop all services
docker compose down

# Stop and remove volumes (careful - this deletes data!)
docker compose down -v
```

### Troubleshooting Communication Issues

**1. Check if services can reach each other:**

```bash
# Get into a running container
docker compose exec backend sh

# Test connection to other services
ping database
ping redis
nslookup frontend
```

**2. Check network connectivity:**

```bash
# List networks
docker network ls

# Inspect network to see connected containers
docker network inspect myproject_frontend_network
```

**3. Check service status:**

```bash
# See all running containers
docker compose ps

# Check container logs
docker compose logs redis
```

**4. Common connection issues:**

- Service names must match exactly (case-sensitive)
- Services must be on the same network to communicate
- Use internal ports (not mapped ports) for service-to-service communication
- Wait for services to be ready (use health checks or retry logic)

## Key Takeaways

1. **Development Tool:** Docker Compose is for development/testing, not production
2. **Service Communication:** Use service names as hostnames for inter-container communication
3. **Environment Variables:** Use them to configure connection strings and URLs
4. **Networks:** Isolate services using custom networks for security
5. **Volumes:** Use bind mounts for development, named volumes for data persistence
6. **Building:** Use `build` instead of `image` when you need custom images
7. **Dependencies:** Use `depends_on` to control startup order (though it doesn't wait for services to be ready)

Remember to always test your setup with `docker compose up` and check logs with `docker compose logs` when troubleshooting!